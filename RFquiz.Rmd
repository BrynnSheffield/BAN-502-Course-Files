## Random Forests

```{r, include = FALSE}
library(titanic)
library(tidyverse)
library(tidymodels)
library(mice) #package for imputation
library(VIM) #visualizing missingness
library(ranger) #for random forests
library(randomForest) #also for random forests
library(caret)
library(vip)
library(gridExtra)
library(ranger)
library(skimr)
```

Read in dataset   
```{r}
drugs =read_csv("drug_data-2.csv")
```

Structure and summary
```{r}
str(drugs)
summary(drugs)
```

Factor conversion and recoding and imputation
```{r}
drugs = drugs %>% mutate(DonatedMarch = as_factor(DonatedMarch))
```

```{r}
names(drugs) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
"Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
"SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
"Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
"LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
```

```{r}
drugs[drugs == "CL0"] = "No"
drugs[drugs == "CL1"] = "No"
drugs[drugs == "CL2"] = "Yes"
drugs[drugs == "CL3"] = "Yes"
drugs[drugs == "CL4"] = "Yes"
drugs[drugs == "CL5"] = "Yes"
drugs[drugs == "CL6"] = "Yes"
```

```{r}
drugs_clean = drugs %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54",
"55_64", "65_"))) %>%
mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18",
"SomeCollege","ProfessionalCert",
"Bachelors", "Masters",
"Doctorate"))) %>%
mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia",
"Ireland","Canada","UK"))) %>%
mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White",
"White/Black", "Other",
"White/Asian", "Black/Asian"))) %>%
mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
select(-ID)
```
```{r}
str(drugs_clean)
```

```{r}
drugs_clean = drugs_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))
```

```{r}
str(drugs_clean)
summary(drugs_clean)
skim(drugs_clean)
```
Splitting.  

```{r}
set.seed(1234)
drugs_split = initial_split(drugs_clean, prop = 0.70, strata = Nicotine)
train = training(drugs_split)
test = testing(drugs_split)
```

Set up our folds for cross-validation  
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```

Random forest with an R-defined tuning grid (this model took about 5 minutes to run)
```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

set.seed(123)
rf_res = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = 10 #try 20 different combinations of the random forest tuning parameters
)
```

Look at parameter performance (borrowed from https://juliasilge.com/blog/sf-trees-random-tuning/)
```{r}
rf_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
Refining the parameters  
```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
An alternate view of the parameters  
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
```

```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf
```
```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)
```

Check out variable importance
```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```

Predictions  
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```

Confusion matrix
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```

Predictions on test
```{r}
testpredrf = predict(final_rf_fit, test)
head(testpredrf)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```

Save the model to a file to load later (if needed)  
```{r}
saveRDS(final_rf_fit, "final_rf_fit.rds")
```

Load the model  
```{r}
final_rf_fit = readRDS("final_rf_fit.rds")
```

